{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "import torch\n",
    "import main as m\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import PILToTensor#, tensor"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "std = torch.tensor([0.229, 0.224, 0.225])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "dt= m.DataAugmentationDINO(\n",
    "  global_crops_scale=(0.8, 1),\n",
    "  local_crops_scale=(0.4, 1),\n",
    "  local_crops_number=2\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "imgs = [Image.open(f) for f in sorted(Path(\"venice\").iterdir()) ]\n",
    "imgs_t = [dt(PILToTensor()(im).permute(1,2,0).unsqueeze(0)) for im in imgs]\n",
    "\n",
    "fig,ax = plt.subplots(ncols=len(imgs), figsize=(5*len(imgs), 5))\n",
    "for i, im in enumerate(imgs_t):\n",
    "  ax[i].imshow((im[0][0].permute(1,2,0) * std) + mean)\n",
    "  ax[i].axis(\"off\")\n",
    "  \n",
    "\n",
    "  \n",
    "(type(imgs_t), len(imgs_t), \"batch\"), (type(imgs_t[0]), len(imgs_t[0]), \"global, local, local\"), ([t.shape for t in imgs_t[0]], \"frames/c/h/w\")  "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "# torch.load(\"checkpoint.pth\")[\"teacher\"].keys()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "model = m.vits.vit_small(patch_size=16, drop_path_rate=0.1)\n",
    "\n",
    "model = m.utils.MultiCropWrapper(\n",
    "  model, \n",
    "  m.DINOHead(\n",
    "      in_dim=model.embed_dim,\n",
    "      out_dim=65536,\n",
    "      use_bn=False\n",
    "  )\n",
    ")\n",
    "model;\n",
    "# model.load_state_dict(torch.load(\"checkpoint.pth\")[\"teacher\"])\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "source": [
    "global_imgs = torch.stack([gll[0] for gll in imgs_t])\n",
    "global_imgs.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "source": [
    "teacher_global, teacher_patches, attn, query, key = model([global_imgs], return_track=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "source": [
    "(\n",
    "  (teacher_global.shape, \"f/b/head_dim\"), # cls token of each image processed through dino head\n",
    "  (teacher_patches.shape, \"f/b/p/(embed_dim*n_heads)\"), # patch tokens\n",
    "  (attn.shape, \"f/b/n_heads/(p+1)*(p+1)\"), # attention maps \n",
    "  (query.shape, \"f/b/n_heads/(p+1)/embed_dim\"), # query vectors\n",
    "  (key.shape, \"f/b/n_heads/(p+1)/embed_dim\") # query vectors\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "source": [
    "masked_img = m.utils.MOT(attn, query, key, teacher_patches, patch_size=16, images=[global_imgs], num_samples=6)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "source": [
    "masked_img.shape, \"num_samples/b/f/c/h/w\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "source": [
    "ns, b, f, c,h,w = masked_img.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "source": [
    "fig, ax =plt.subplots(ncols=b,nrows=ns, figsize=(5*b, 5*ns))\n",
    "\n",
    "for i in range(ns):\n",
    "  for j in range(b):\n",
    "    ax[i,j].imshow((masked_img.detach()[i,j,0].permute(1,2,0) * std)+mean)\n",
    "    ax[i,j].axis(\"off\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uj",
   "language": "python",
   "name": "uj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
